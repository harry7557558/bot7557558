{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making statements based on opinion; back them up with references or personal experience.\n",
      "Disney's Frozen represents a landmark for the animation giant due not only to its immense popularity but also its introduction of the studio's first disabled princess. In order to make Elsa's story possible, the animators use a combination of narrative devices including the introduction of a second princess, whose story fulfills the audience's expectation for a traditional \"princess journey,\" their patented aesthetic of cuteness, and the encoding of disability as fantasy. Although Elsa's disability is encoded as a magical ice power, the language the film uses to talk about her condition maps on to the experiences of people with physical, mental, and intellectual disabilities in recognizable ways. Meanwhile, her status as a much-beloved princess figure allows the animators at Disney to position disability as a universal experience and in turn to create empathy for PWDs both on and off screen.\n",
      "<<Compute cosine term of Oren-Nayar model>>=\n",
      "Uniform and symmetric moment load [ edit ]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "def load_data(filename):\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "    lines = [line.strip() for line in lines]\n",
    "    lines = [line for line in lines if line != \"\"]\n",
    "    random.shuffle(lines)\n",
    "    return lines\n",
    "\n",
    "content = load_data(\"content.txt\")\n",
    "unwanted = load_data(\"unwanted.txt\")\n",
    "print('\\n'.join(content[:2]))\n",
    "print('\\n'.join(unwanted[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.45160e+04 2.12000e+02 2.06700e+03 1.00000e+02 1.80000e+01 7.62000e+02\n",
      " 5.91000e+02 5.90000e+02 2.00000e+00 2.80000e+01 6.65100e+03 1.04500e+03\n",
      " 4.28500e+03 4.90000e+01 3.35200e+03 1.45000e+02 4.86000e+02 3.00000e+00\n",
      " 5.70000e+01 1.00000e+00 2.99000e+02 1.23640e+04 2.20000e+02 4.19000e+02\n",
      " 2.20000e+02 7.90000e+01 2.42000e+02 3.85363e+05 1.42000e+02 1.42000e+02]\n",
      "[1.3062e+04 1.4000e+01 4.3900e+02 1.4100e+02 7.2000e+01 2.7600e+02\n",
      " 4.2800e+02 4.2800e+02 4.0000e+01 9.9000e+01 1.2270e+03 2.7800e+02\n",
      " 1.3190e+03 5.0000e+01 3.9640e+03 2.2000e+02 7.5000e+01 5.0000e+01\n",
      " 1.2200e+02 7.6000e+01 1.3000e+01 8.2940e+03 4.9000e+01 4.7600e+02\n",
      " 4.9000e+01 2.1800e+02 1.4900e+02 4.7826e+04 2.8800e+02 2.8700e+02]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "key_chars = \"\"\" !\"$&'()*+,-./0:;<=>?A[\\\\]^_a{}\"\"\"\n",
    "\n",
    "def vectorize(s):\n",
    "    s = re.sub(r\"[a-z]\", 'a', s)\n",
    "    s = re.sub(r\"[A-Z]\", 'A', s)\n",
    "    s = re.sub(r\"[0-9]\", '0', s)\n",
    "    s = re.sub(r\"\\s\", ' ', s)\n",
    "    counts = dict(zip(key_chars, [0]*len(key_chars)))\n",
    "    for c in s:\n",
    "        if c in counts:\n",
    "            counts[c] += 1\n",
    "    return np.array([counts[c] for c in key_chars], dtype=np.float32)\n",
    "\n",
    "print(vectorize(''.join(content)))\n",
    "print(vectorize(''.join(unwanted)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Net(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n",
      "test (50): 0.14024344 0.96875\n",
      "test (100): 0.12551524 0.96875\n",
      "test (150): 0.121369 0.96875\n",
      "test (200): 0.11962508 0.96875\n",
      "test (250): 0.118796125 0.96875\n",
      "test (300): 0.118389495 0.96875\n",
      "test (350): 0.11818839 0.96875\n",
      "test (400): 0.11808909 0.96875\n",
      "test (450): 0.11804059 0.96875\n",
      "test (500): 0.11801704 0.96875\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(content) + len(unwanted)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if i < len(content):\n",
    "            return vectorize(content[i]), \\\n",
    "                np.array([1.], dtype=np.float32)\n",
    "        return vectorize(unwanted[i-len(content)]), \\\n",
    "            np.array([0.], dtype=np.float32)\n",
    "\n",
    "dataloader = DataLoader(MyDataset(), batch_size=32, shuffle=True)\n",
    "dataloader = [d for d in dataloader]\n",
    "test_data = dataloader[0]\n",
    "train_data = dataloader[1:]\n",
    "print(test_data[0].shape[1])\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(test_data[0].shape[1], 1, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "for epoch in range(500):\n",
    "    for x, y in train_data:\n",
    "        net.zero_grad()\n",
    "        err = loss(net(x), y)\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "    predicted = net(test_data[0])\n",
    "    actual = test_data[1]\n",
    "    err = loss(predicted, actual).detach().numpy()\n",
    "    accuracy = np.mean((torch.round(predicted) == actual).detach().numpy())\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f\"test ({epoch+1}):\", np.mean(err), accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': -0.0085, '!': 1.8875, '\"': 0.9782, '$': -0.1644, '&': 0.5831, \"'\": -0.6959, '(': -0.0929, ')': -0.0961, '*': 0.428, '+': -0.2615, ',': 0.0972, '-': 0.4882, '.': 0.3976, '/': 0.0095, '0': -0.3535, ':': -0.1494, ';': 0.5223, '<': 0.3736, '=': 0.2193, '>': -2.1398, '?': 3.2519, 'A': -0.3841, '[': 0.2734, '\\\\': -0.1707, ']': 0.5493, '^': 0.7976, '_': -0.6222, 'a': 0.0509, '{': 0.0975, '}': -0.1276}\n",
      "-1.2\n",
      "-3.1205 MOANA\n",
      "-1.3805 Moana\n",
      "-1.2761 I am Moana of Motunui.\n",
      "2.7875 Do you want to build a snowman?\n",
      "0.4846 I am a sussy programmer writing sussy code.\n",
      "1.7608 What's wrong with you?\n",
      "1.3641 Creates a criterion that measures the Binary Cross Entropy between the target and the input probabilities:\n",
      "-1.3235 Table of Contents\n",
      "-2.0935 https://harry7557558.github.io\n",
      "-1.3672 1.1 4th-Order Partial Differential Equations\n",
      "-1.0493 4th-Order Partial Differential Equations\n",
      "0.6907 4th-order partial differential equations\n",
      "-0.8504 From Wikipedia, the Free Encyclopedia.\n",
      "0.0196 From Wikipedia, the free encyclopedia.\n",
      "-4.0454 Harry Chen - Updated 12/30/2022\n",
      "0.3583 Note: This tool is recently under active development.\n",
      "0.0301 initialize WebGL: load and compile shader, initialize buffers\n",
      "0.7585 tell WebGL how to pull out the positions from the position buffer into the vertexPosition\n",
      "-0.4912 ## A list/backup of my saved Desmos graphs\n",
      "-0.7183 spiral, logarithmic, interior, beach, nautilus, seashell, conch • 2021/09/12 • public+api\n",
      "1.4569 Debugging an SDF, try to use a previous volume rendering shader to visualize its discontinuity.\n",
      "3.0801 [6] A. Witkin, \"Physically based modeling: Particle system dynamics,\" https://graphics.pixar.com/pbm2001/pdf/notesc.pdf, 2001.\n",
      "3.8403 Kierkegaard, Søren Aabye. Source of Søren Kierkegaard Quote. College of Liberal Arts & Sciences, The University of Iowa, https://homepage.math.uiowa.edu/~jorgen/kierkegaardquotesource.html.\n",
      "-3.4775 T=2\\pi\\sqrt{\\frac{L}{g}}\\left(1+\\frac{1}{16}\\theta^2+\\mathrm{O}\\left(\\theta^4\\right)\\right)\n",
      "-1.373 The Preconditioned Conjugate Gradient Method\n"
     ]
    }
   ],
   "source": [
    "ws = []\n",
    "for param in net.parameters():\n",
    "    weights = param.data\n",
    "    ws.append(weights.numpy())\n",
    "weights = [round(w, 4) for w in ws[0][0].tolist()]\n",
    "weights = dict(zip(key_chars, weights))\n",
    "bias = round(ws[1][0], 4)\n",
    "bias = -1.2\n",
    "print(weights)\n",
    "print(bias)\n",
    "\n",
    "def predict(s):\n",
    "    s0 = s\n",
    "    s = re.sub(r\"[a-z]\", 'a', s)\n",
    "    s = re.sub(r\"[A-Z]\", 'A', s)\n",
    "    s = re.sub(r\"[0-9]\", '0', s)\n",
    "    s = re.sub(r\"\\s\", ' ', s)\n",
    "    total = bias\n",
    "    for c in s:\n",
    "        if c in weights:\n",
    "            total += weights[c]\n",
    "    print(round(total, 4), s0)\n",
    "\n",
    "predict(\"MOANA\")\n",
    "predict(\"Moana\")\n",
    "predict(\"I am Moana of Motunui.\")\n",
    "predict(\"Do you want to build a snowman?\")\n",
    "predict(\"I am a sussy programmer writing sussy code.\")\n",
    "predict(\"What's wrong with you?\")\n",
    "predict(\"Creates a criterion that measures the Binary Cross Entropy between the target and the input probabilities:\")\n",
    "predict(\"Table of Contents\")\n",
    "predict(\"https://harry7557558.github.io\")\n",
    "predict(\"1.1 4th-Order Partial Differential Equations\")\n",
    "predict(\"4th-Order Partial Differential Equations\")\n",
    "predict(\"4th-order partial differential equations\")\n",
    "predict(\"From Wikipedia, the Free Encyclopedia.\")\n",
    "predict(\"From Wikipedia, the free encyclopedia.\")\n",
    "predict(\"Harry Chen - Updated 12/30/2022\")\n",
    "predict(\"Note: This tool is recently under active development.\")\n",
    "predict(\"initialize WebGL: load and compile shader, initialize buffers\")\n",
    "predict(\"tell WebGL how to pull out the positions from the position buffer into the vertexPosition\")\n",
    "predict(\"## A list/backup of my saved Desmos graphs\")\n",
    "predict(\"spiral, logarithmic, interior, beach, nautilus, seashell, conch • 2021/09/12 • public+api\")\n",
    "predict(\"Debugging an SDF, try to use a previous volume rendering shader to visualize its discontinuity.\")\n",
    "predict(\"[6] A. Witkin, \\\"Physically based modeling: Particle system dynamics,\\\" https://graphics.pixar.com/pbm2001/pdf/notesc.pdf, 2001.\")\n",
    "predict(\"Kierkegaard, Søren Aabye. Source of Søren Kierkegaard Quote. College of Liberal Arts & Sciences, The University of Iowa, https://homepage.math.uiowa.edu/~jorgen/kierkegaardquotesource.html.\")\n",
    "predict(\"T=2\\pi\\sqrt{\\\\frac{L}{g}}\\left(1+\\\\frac{1}{16}\\\\theta^2+\\mathrm{O}\\left(\\\\theta^4\\\\right)\\\\right)\")\n",
    "predict(\"The Preconditioned Conjugate Gradient Method\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ecbc50d119a157bb487b95c6f0c652477a8946cf907138d6308c321abbbf8dc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
